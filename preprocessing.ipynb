{
 "cells": [
  {
   "cell_type": "code",
   "id": "442d5b98aac98c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T20:44:43.541939Z",
     "start_time": "2025-02-02T20:44:25.412556Z"
    }
   },
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T20:57:31.599003Z",
     "start_time": "2025-02-02T20:56:44.454223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directories\n",
    "DATA_DIR = \"data/outfits\"\n",
    "OUTPUT_DIR = \"./processed_data\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize Pose Estimation (MediaPipe)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Load Segmentation Model (Segment Anything)\n",
    "sam_checkpoint = \"./models/sam_vit_h.pth\"\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=sam_checkpoint)\n",
    "sam_predictor = SamPredictor(sam)\n",
    "\n",
    "# Perspective Correction: Define a Reference Posture (Standardized Bounding Box)\n",
    "REF_WIDTH = 256\n",
    "REF_HEIGHT = 512\n",
    "REF_POINTS = np.float32([[50, 50], [200, 50], [50, 450], [200, 450]])  # Reference points for alignment"
   ],
   "id": "19e68641a3641e83",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738529804.710656 9263715 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M3\n",
      "W0000 00:00:1738529804.844695 9283767 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1738529804.862853 9283761 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T20:58:04.331767Z",
     "start_time": "2025-02-02T20:58:04.296461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformation Function\n",
    "def perspective_correction(image, keypoints):\n",
    "    if keypoints is None:\n",
    "        return image  # Skip if no pose detected\n",
    "\n",
    "    # Select 4 key body landmarks for transformation\n",
    "    src_points = np.float32([\n",
    "        keypoints[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "        keypoints[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "        keypoints[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "        keypoints[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "    ])\n",
    "\n",
    "    # Compute homography and apply transformation\n",
    "    matrix = cv2.getPerspectiveTransform(src_points, REF_POINTS)\n",
    "    corrected_image = cv2.warpPerspective(image, matrix, (REF_WIDTH, REF_HEIGHT))\n",
    "\n",
    "    return corrected_image\n",
    "\n",
    "# Segmentation Function\n",
    "def segment_outfit(image):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    sam_predictor.set_image(image_rgb)\n",
    "    masks, _, _ = sam_predictor.predict()\n",
    "    \n",
    "    if masks is not None:\n",
    "        return masks[0]  # Return the first segmentation mask\n",
    "    return None"
   ],
   "id": "bcca993054fdde81",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-02T21:55:32.477822Z",
     "start_time": "2025-02-02T20:59:10.125392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main Processing Loop\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "    \n",
    "    image_path = os.path.join(DATA_DIR, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Warning: Failed to load image {filename}. Skipping...\")\n",
    "        continue  # Skip processing this file\n",
    "\n",
    "    # Proceed with the rest of the pipeline\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        # Extract Keypoints\n",
    "        keypoints = [(int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0]))\n",
    "                     for landmark in results.pose_landmarks.landmark]\n",
    "        \n",
    "        # Perspective Correction\n",
    "        corrected_image = perspective_correction(image, keypoints)\n",
    "\n",
    "        # Segmentation\n",
    "        mask = segment_outfit(corrected_image)\n",
    "        if mask is not None:\n",
    "            segmented_outfit = cv2.bitwise_and(corrected_image, corrected_image, mask=mask.astype(np.uint8))\n",
    "        else:\n",
    "            segmented_outfit = corrected_image\n",
    "\n",
    "        # Save Processed Image\n",
    "        output_path = os.path.join(OUTPUT_DIR, filename)\n",
    "        cv2.imwrite(output_path, segmented_outfit)\n",
    "        print(f\"Processed {filename} -> {output_path}\")\n",
    "\n",
    "print(\"Preprocessing Complete!\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to load image elegant outfit woman_3.jpg. Skipping...\n",
      "Processed elegant outfit woman_1.jpg -> ./processed_data/elegant outfit woman_1.jpg\n",
      "Processed elegant outfit woman_4.jpg -> ./processed_data/elegant outfit woman_4.jpg\n",
      "Processed elegant outfit woman_5.jpg -> ./processed_data/elegant outfit woman_5.jpg\n",
      "Processed casual outfit woman_9.jpg -> ./processed_data/casual outfit woman_9.jpg\n",
      "Processed elegant outfit woman_7.jpg -> ./processed_data/elegant outfit woman_7.jpg\n",
      "Processed elegant outfit woman_6.jpg -> ./processed_data/elegant outfit woman_6.jpg\n",
      "Processed casual outfit woman_8.jpg -> ./processed_data/casual outfit woman_8.jpg\n",
      "Processed elegant outfit woman_10.jpg -> ./processed_data/elegant outfit woman_10.jpg\n",
      "Processed casual outfit woman_10.jpg -> ./processed_data/casual outfit woman_10.jpg\n",
      "Processed casual outfit woman_11.jpg -> ./processed_data/casual outfit woman_11.jpg\n",
      "Processed elegant outfit woman_11.jpg -> ./processed_data/elegant outfit woman_11.jpg\n",
      "Processed casual outfit woman_13.jpg -> ./processed_data/casual outfit woman_13.jpg\n",
      "Processed elegant outfit woman_13.jpg -> ./processed_data/elegant outfit woman_13.jpg\n",
      "Processed outfit inspiration_5.jpg -> ./processed_data/outfit inspiration_5.jpg\n",
      "Processed outfit inspiration_4.jpg -> ./processed_data/outfit inspiration_4.jpg\n",
      "Processed elegant outfit woman_12.jpg -> ./processed_data/elegant outfit woman_12.jpg\n",
      "Processed outfit inspiration_1.jpg -> ./processed_data/outfit inspiration_1.jpg\n",
      "Warning: Failed to load image elegant outfit woman_15.jpg. Skipping...\n",
      "Warning: Failed to load image casual outfit woman_15.jpg. Skipping...\n",
      "Processed outfit inspiration_3.jpg -> ./processed_data/outfit inspiration_3.jpg\n",
      "Processed outfit inspiration_2.jpg -> ./processed_data/outfit inspiration_2.jpg\n",
      "Processed elegant outfit woman_14.jpg -> ./processed_data/elegant outfit woman_14.jpg\n",
      "Processed casual outfit woman_4.jpg -> ./processed_data/casual outfit woman_4.jpg\n",
      "Processed casual outfit woman_6.jpg -> ./processed_data/casual outfit woman_6.jpg\n",
      "Processed elegant outfit woman_8.jpg -> ./processed_data/elegant outfit woman_8.jpg\n",
      "Processed elegant outfit woman_9.jpg -> ./processed_data/elegant outfit woman_9.jpg\n",
      "Processed casual outfit woman_7.jpg -> ./processed_data/casual outfit woman_7.jpg\n",
      "Processed casual outfit woman_3.jpg -> ./processed_data/casual outfit woman_3.jpg\n",
      "Processed casual outfit woman_2.jpg -> ./processed_data/casual outfit woman_2.jpg\n",
      "Processed casual outfit woman_1.jpg -> ./processed_data/casual outfit woman_1.jpg\n",
      "Preprocessing Complete!\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
